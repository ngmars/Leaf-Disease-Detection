{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(directory= r\"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\",\n",
    "                                       target_size=(224,224))\n",
    "\n",
    "tsdata = ImageDataGenerator()\n",
    "validdata = tsdata.flow_from_directory(directory=r\"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\",\n",
    "                                     target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (traindata.class_indices) #classes and their indices\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16 = VGG16(include_top=False, weights='imagenet',input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze all the layers, as non-trainable\n",
    "for layer in vgg_16.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Model summary\n",
    "vgg_16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Layers to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add the vgg base \n",
    "model.add(vgg_16)\n",
    "print(\"Shape:\",model.output_shape)\n",
    "\n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "print(\"Shape:\",model.output_shape)\n",
    "\n",
    "model.add(Dense(38, activation='softmax'))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "      optimizer= optimizers.Adam(lr=0.00001),\n",
    "      metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=50)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=0.000001, verbose=1)\n",
    "cp = ModelCheckpoint(filepath=\"/kaggle/working/best_weights.hdf5\", \n",
    "                               monitor = 'val_acc',\n",
    "                               verbose=1, \n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    traindata,\n",
    "    batch_size=500,\n",
    "    epochs=1,\n",
    "    callbacks=[es,rlr, cp],\n",
    "    validation_data=validdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(r'../input/savedmodel/best_weights.hdf5')\n",
    "model.save(r'/kaggle/working/best-model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../input/savedmodel/best-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testimage(img):    \n",
    "    plt.imshow(img)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    class_index = model.predict_classes(images, batch_size=10)\n",
    "    for name, index in label_map.items():\n",
    "        if index == class_index[0]:\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test image and call the function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(r'../input/new-plant-diseases-dataset/test/test/TomatoHealthy3.JPG', target_size=(224, 224))\n",
    "testimage(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceimg = np.copy(img)\n",
    "R, G, B = cv2.split(sourceimg)\n",
    "\n",
    "output1_R = cv2.equalizeHist(R)\n",
    "output1_G = cv2.equalizeHist(G)\n",
    "output1_B = cv2.equalizeHist(B)\n",
    "\n",
    "equ = cv2.merge((output1_R, output1_G, output1_B))\n",
    "testimage(equ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict_generator(validdata)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "cm = (confusion_matrix(validdata.classes, y_pred))\n",
    "\n",
    "for i in cm:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colour Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For arbitrary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(sourceimg, cv2.COLOR_RGB2BGR)\n",
    "hsv = cv2.cvtColor(sourceimg, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# find the green color \n",
    "mask_green = cv2.inRange(hsv, (36,0,0), (86,255,255))\n",
    "# find the brown color\n",
    "mask_brown = cv2.inRange(hsv, (8, 60, 20), (30, 255, 200))\n",
    "# find the yellow color in the leaf\n",
    "mask_yellow = cv2.inRange(hsv, (21, 39, 64), (40, 255, 255))\n",
    "\n",
    "# find any of the three colors(green or brown or yellow) in the image\n",
    "mask = cv2.bitwise_or(mask_green, mask_brown)\n",
    "mask = cv2.bitwise_or(mask, mask_yellow)\n",
    "\n",
    "# Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(sourceimg,sourceimg, mask=mask)\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
